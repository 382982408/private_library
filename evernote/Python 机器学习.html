<html>
<head>
  <title>Python 机器学习</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/600753 (zh-CN, DDL); Windows/10.0.0 (Win64);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="468"/>
<h1>Python 机器学习</h1>

<div>
<span><div><div style="margin: 0mm 0mm 3.52mm; text-indent: 0mm; padding-top: 0mm; padding-bottom: 0mm; min-height: 23pt;"><span style="text-indent: 0mm; min-height: 23pt;"><span style="font-size: 16pt; color: rgb(46, 46, 46); font-family: &quot;Times New Roman&quot;; font-weight: bold; line-height: 23pt;">Python 机器学习</span></span></div><div style="margin: 0mm 0mm 3.52mm; text-indent: 0mm; padding-top: 0mm; padding-bottom: 0mm; min-height: 23pt;"><span style="font-size: 16pt;"><span style="font-size: 16pt; color: rgb(46, 46, 46); font-family: &quot;Times New Roman&quot;; font-weight: bold;"><img src="Python 机器学习_files/Image.png" type="image/png" data-filename="Image.png" width="459"/></span></span></div><div><span style="color: rgb(227, 0, 0); font-family: &quot;Times New Roman&quot;; font-weight: bold;">1）为什么要用numpy.array ?python  不是有list 了吗？</span></div><div><span style="color: rgb(1, 1, 1); font-family: &quot;Times New Roman&quot;; font-weight: bold;">    Python中提供了list容器，可以当作数组使用。但列表中的元素可以是任何对象，因此列表中保存的是对象的指针，这样一来，为了保存一个简单的列表[1,2,3]。就需要三个指针和三个整数对象。对于数值运算来说，这种结构显然不够高效。</span><span style="color: rgb(1, 1, 1); font-family: &quot;Times New Roman&quot;; font-weight: bold;">Python虽然也提供了array模块，但其只支持一维数组，不支持多维数组(在TensorFlow里面偏向于矩阵理解)，也没有各种运算函数。因而不适合数值运算。</span><span style="color: rgb(1, 1, 1); font-family: &quot;Times New Roman&quot;; font-weight: bold;">NumPy的出现弥补了这些不足。</span></div><div><br clear="none"/></div><h2><span style="font-size: 10pt;"><span style="font-size: 10pt;"><span style="font-size: 10pt; color: rgb(227, 0, 0); font-family: &quot;Times New Roman&quot;; font-weight: bold;">2）机器学习模块须知</span></span></span></h2><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-weight: bold;">1.1)Pandas 数据碰撞模块，比如pandas. read_csv,Series 和 Dataframe 很重要  </span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-weight: bold;">1.2)Numpy 数据处理模块，比如numpy.array()；转化数据为向量格式</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-weight: bold;">1.3)Science-kit-learn 模块，from sklearn import linear_model；回归模块；</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-weight: bold;">1.4)Matplotlib 作图模块；</span></div><div><span style="font-size: 10pt;"><br clear="none"/></span></div><h3><span style="font-size: 10pt;"><span style="font-size: 10pt; color: rgb(227, 0, 0); font-family: &quot;Times New Roman&quot;; font-weight: bold;">3）常见机器学习算法名单，</span></span><span style="font-size: 10pt; color: rgb(227, 0, 0); font-family: &quot;Times New Roman&quot;;">可以分为四组：分类，聚类，回归和降维。</span></h3><div><span style="font-size: 10pt; color: rgb(46, 46, 46); font-family: &quot;Times New Roman&quot;;">这里是一个常用的机器学习算法名单。这些算法几乎可以用在所有的数据问题上。</span></div><div><a href="https://www.cnblogs.com/en-heng/p/5013995.html" shape="rect" style="font-family: &quot;Times New Roman&quot;;">https://www.cnblogs.com/en-heng/p/5013995.html</a></div><div><span style="font-size: 10pt; color: rgb(1, 1, 1); font-family: 微软雅黑; font-weight: bold;">1）分类算法</span></div><div><span style="font-size: 10pt;"><span style="font-size: 10pt; color: rgb(255, 0, 0); font-family: &quot;Times New Roman&quot;; font-weight: bold;"> </span> <span style="font-size: 10pt; color: rgb(255, 0, 0); font-family: &quot;Times New Roman&quot;; font-weight: bold;">   1.1 </span></span><span style="font-size: 10pt;"><span style="font-size: 10pt; color: rgb(255, 0, 0); font-family: &quot;Times New Roman&quot;;">决策树</span><span style="font-size: 10pt; color: rgb(255, 0, 0); font-family: &quot;Times New Roman&quot;;">。</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;"> </span></span><span style="font-size: 10pt; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">C4.5</span><span style="font-size: 10pt; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">算法是</span><a href="http://lib.csdn.net/base/machinelearning" shape="rect" style="font-size: 10pt; box-sizing: border-box; outline: 0px; cursor: pointer; word-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;" title="机器学习知识库">机</a><a href="http://lib.csdn.net/base/machinelearning" shape="rect" style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">器学习</a><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">算法<span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">中的</span></span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">一种分类决策树算法,其核心算法是ID3算法。</span></span> 决策树（decision tree）算法基于特征属性进行分类，其主要的优点：模型具有可读性，计算量小，分类速度快、白箱操作、<span style="color: rgb(227, 0, 0);">特征条件有关联的场景下也可适用</span>。</div><div>          特征选择的过程等同于计算每个特征的信息增益，选择最大信息增益的特征进行分裂。</div><div>          <img src="Python 机器学习_files/Image [1].png" type="image/png" data-filename="Image.png" width="286"/></div><div>        为了衡量类别分布概率的倾斜程度，定义决策树节点t的不纯度（impurity），其满足：不纯度越小，则类别的分布概率越倾斜；下面给出不纯度的的三种度量：</div><div>           <img src="Python 机器学习_files/Image [2].png" type="image/png" data-filename="Image.png" width="232"/></div><div>        说简单点就是计算每个分类特征分类前后的香农熵，香农熵减少量越多，则信息增益越大，则选择次特征为分类节点。</div><div><a href="https://www.cnblogs.com/ahu-lichang/p/7169026.html" shape="rect">    https://www.cnblogs.com/ahu-lichang/p/7169026.html</a></div><div><br clear="none"/></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">     1.2 </span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">K近邻算</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">法--KNN</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">为监督学习中的分类算法</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">。<span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; color: rgb(227, 0, 0);">缺点：分类效率低、耗时长。</span></span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">     1.3 </span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">支持向量机--SVM。</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">     <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; color: rgb(227, 0, 0);">1.4 朴</span></span><span style="font-size: 10pt; color: rgb(227, 0, 0); font-family: &quot;Times New Roman&quot;;">素贝叶斯--</span> <span style="font-size: 10pt;"><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; color: rgb(227, 0, 0); font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">Naive Bayesian</span></span> <span style="font-size: 10pt;"><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;"><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal; color: rgb(227, 0, 0);">Model，NBC</span>。</span></span> 朴素贝叶斯（Naïve Bayes）属于监督学习的生成模型，实现简单，没有迭代，学习效率高，在大样本量下会有较好的表现。但因为假设太强——假设特征条件独立，在输入向量的<span style="color: rgb(227, 0, 0);">特征条件有关联的场景下不适用。</span><span style="font-family: &quot;Times New Roman&quot;;">该算法能</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">运用到大型数据库中，而且方法简单、分类准确率高、速度快。</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 28px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">贝叶斯定理公式:P(A|B)=P(B|A)*P(A)/P(B)</span></span><span style="letter-spacing: normal; orphans: 2; text-indent: 28px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">，</span></span><span style="letter-spacing: normal; orphans: 2; text-indent: 28px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">后验概率 = (似然度 * 先验概率)/标准化常量</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">。</span></div><div><span style="font-size: 11pt; color: rgb(227, 0, 0); font-family: arial;">        </span><a href="Python 机器学习_files/bayes_classfication.py"><img src="Python 机器学习_files/16365a636af6cfa6d8f45e5a18e5bc04.png" alt="bayes_classfication.py"></a></div><div><span style="color: rgb(227, 0, 0);">   </span> <span style="font-size: 10pt;"><span style="font-size: 10pt; color: rgb(227, 0, 0); font-family: &quot;Times New Roman&quot;;"> 1.5 </span></span> <span style="font-size: 10pt;"><span style="letter-spacing: normal; orphans: 2; text-indent: 28px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 10pt; color: rgb(227, 0, 0); font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">神经网络分类算法</span></span></span><span style="font-family: &quot;Times New Roman&quot;;">。 </span></div><div><span style="font-size: 10pt;"><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt;"><br clear="none"/></span></span></div><div><span style="font-size: 10pt; color: rgb(1, 1, 1); font-family: 微软雅黑; font-weight: bold;">2）聚类算法</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-weight: bold;">     2.1  </span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">K均值算法，</span> <span style="font-size: 10pt; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">即K-Means算</span><span style="font-size: 10pt;"><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">法，</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">是非监<span style="font-size: 10pt; background-color: rgb(245, 245, 245); font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">督学习中的聚类算法，与KNN均是</span></span></span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); font-size: 10pt; color: rgb(0, 0, 0); font-family: &quot;Microsoft Yahei&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">利用近邻信息来标注类别</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">。</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(245, 245, 245); font-size: 10pt; color: rgb(0, 0, 0); font-family: &quot;Microsoft Yahei&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">k-means是聚类算法中最为简单、高效的。</span></div><div><span style="color: rgb(1, 1, 1); font-weight: bold;">3）回归算法</span></div><div>    3.1 <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">线性回归</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">     3.2 </span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">逻辑回归</span></div><div><span style="font-weight: bold;">4）降维算法</span></div><div><br clear="none"/></div><div><span style="font-size: 10pt;"><span style="font-size: 10pt; font-weight: bold;">5）关联分析算法</span></span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;"> </span> <span style="font-size: 10pt; color: rgb(255, 0, 0); font-family: &quot;Times New Roman&quot;;">  5.1 </span><span style="font-size: 10pt; color: rgb(255, 0, 0); font-family: &quot;Times New Roman&quot;;">Apriori（prior 在前的较早的）</span><span style="font-size: 10pt; color: rgb(255, 0, 0); font-family: &quot;Times New Roman&quot;;">,</span> <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">该算法也是在一堆数据集中寻</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">找数据之间的某种关联( 频繁项集、关联规则).</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">那如何定义和表示频繁项集和关联规则呢？这里引入支持度和可信度（置信度）。</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">       </span> <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-weight: bold;">频繁项集</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">：经常出现在一块的物品的集合。</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">       </span> <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-weight: bold;">关联规则</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">：暗示两种物品之间可能存在很强的关系。</span></div><div><span style="font-size: 10pt;"><span style="box-sizing: border-box; outline: 0px; word-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">        支持度：P{A,B}，</span></span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">项</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">集出现的概率。</span></div><div><span style="font-size: 10pt;"><span style="box-sizing: border-box; outline: 0px; word-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">        可信度（置信度）：</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">支持度P{A，B}/支持度P{A}，同时出现A、B的概率，出现A的概率（默认0.7）。</span></span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">        </span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;; font-weight: bold;">提升度</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">：体现A和B之间的关联关系，大于1A和B之间具有强关联关系，否则表示无有效的强关联关系。</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">                </span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">提升度=</span><span style="font-size: 10pt; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">P{A，B}/(支持度P{A} *</span> <span style="font-size: 10pt; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">支持度P{B}</span><span style="font-size: 10pt; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-family: &quot;Times New Roman&quot;; font-variant-caps: normal; font-variant-ligatures: normal;">)</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;"> </span> <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">  5.1.1 具体算法，寻找频繁项集的主要步骤：</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">   </span> <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">5.1.1.1</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">首先会生成所有单个物品的项集列表</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">。</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">   </span> <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">5.1.1.2 </span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">扫描交易记录来查看哪些项集满足最小支持度要求，那些不满足最小支持度的集合会被去掉</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">。</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">   </span> <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">5.1.1.3 </span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">对剩下的集合进行组合以生成包含两个元素的项集</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">。</span></div><div><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">   </span> <span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">5.1.1.</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">4 接下来重新扫描交易记录，去掉不满足最小支持度的项集，重复进行直到所有项集都被去掉</span><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">。</span></div><div><span style="font-size: 12pt;"><a href="Python 机器学习_files/apriori.py"><img src="Python 机器学习_files/1d18a3a36bfd0dd48f3ed8d3122987dd.png" alt="apriori.py"></a></span></div><ol style="margin-top: 0mm; margin-bottom: 0mm; margin-left: 0mm; padding-left: 0pt;"><li style="margin-left: 20pt; margin-right: 0pt; padding-left: 0pt; text-indent: 0pt;"><div style="margin-top: 0pt; margin-bottom: 4pt;"><span style="font-size: 10pt; text-indent: 0pt; font-family: &quot;Times New Roman&quot;;">随机森林算法</span></div></li><li style="margin-left: 20pt; margin-right: 0pt; padding-left: 0pt; text-indent: 0pt;"><div style="margin-top: 0pt; margin-bottom: 4pt;"><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">降维算法</span></div></li><li style="margin-left: 20pt; margin-right: 0pt; padding-left: 0pt; text-indent: 0pt;"><div style="margin-top: 0pt; margin-bottom: 4pt;"><span style="font-size: 10pt; font-family: &quot;Times New Roman&quot;;">Gradient Boost 和 Adaboost 算法</span></div></li></ol><div style="margin: 0mm 0mm 3.52mm; text-indent: 0mm; padding-top: 0mm; padding-bottom: 0mm; min-height: 13pt;"><span style="text-indent: 0mm; min-height: 13pt;"><span style="font-size: 10pt; line-height: 13pt;"> </span></span></div><div><br clear="none"/></div><div><br clear="none"/></div><div><br clear="none"/></div><div><br clear="none"/></div></div><div><br clear="none"/></div><div><br/></div><div><br/></div></span>
</div></body></html> 